{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Photon: Automatically visualize patient and virus data for personalized COVID-19 care\n",
    "\n",
    "Out task here is to take an arbitrary tabular data table and make the kinds of design decisions that a human would make to visualize key aspects of that data.  The application is COVID-19 care. Imagine a doctor queries a database to get available data on a patient, thier medical history, their genetics, and the virus strain they have. We don't know what form that comes in, but we want to present a relevant and actionable visualization of the data to inform personalized care. The first step is deciding what kind of visualization to make. \n",
    "\n",
    "We've already calculated over 800 features for each of about 100k tabular datasets with corresponding human-designed visualizations from the plotly community feed. \n",
    "\n",
    "In this notebook, we'll take those features and see if we can predict the chart type a human would have made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import util as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some important variables\n",
    "model_prefix = 'agg'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "features_directory = '../features/processed'\n",
    "saves_directory = './saves'\n",
    "num_datapoints = None  # None if you want all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this script tests aggregate features over line, scatter, and bar outcomes\n",
    "# borrowed from vizML\n",
    "def load_features():\n",
    "    features_df_file_name = 'features_aggregate_single.csv'\n",
    "    outcomes_df_file_name = 'chart_outcomes.csv'\n",
    "\n",
    "    features_df = pd.read_csv(\n",
    "        os.path.join(\n",
    "            features_directory,\n",
    "            features_df_file_name))\n",
    "    outcomes_df = pd.read_csv(\n",
    "        os.path.join(\n",
    "            features_directory,\n",
    "            outcomes_df_file_name))\n",
    "\n",
    "    features_df = features_df[:num_datapoints]\n",
    "    outcome_variable_name = 'all_one_trace_type'\n",
    "    # photon: add circos here? \n",
    "    outcomes = ['line', 'scatter', 'bar']\n",
    "    outcomes_df_subset = outcomes_df[outcomes_df[outcome_variable_name].isin(\n",
    "        outcomes)][['fid', outcome_variable_name]]\n",
    "\n",
    "    final_df = pd.merge(features_df, outcomes_df_subset, on='fid', how='inner')\n",
    "    final_df = final_df.drop(['fid'], axis=1, inplace=False, errors='ignore')\n",
    "    final_df.sample(frac=1.0)\n",
    "\n",
    "    last_index = final_df.columns.get_loc(outcome_variable_name)\n",
    "    X = final_df.iloc[:, :last_index]\n",
    "    y = final_df.iloc[:, last_index]\n",
    "    y = pd.get_dummies(y).values.argmax(1)\n",
    "\n",
    "    res = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "    X, y = res.fit_sample(X, y)\n",
    "    # shuffle X and y in unison, and then return\n",
    "    return util.unison_shuffle(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape is  (210, 657) y shape is  (210,)\n"
     ]
    }
   ],
   "source": [
    "# load_features will do the work for us.\n",
    "X, y = load_features()\n",
    "print(\"X shape is \", X.shape, \"y shape is \", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these are all type float\n",
    "X = X.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 2, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 1, 0, 2,\n",
       "       0, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 2, 1, 0, 2, 0,\n",
       "       2, 2, 0, 2, 2, 0, 1, 1, 1, 0, 2, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0,\n",
       "       0, 1, 2, 2, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 2,\n",
       "       1, 0, 0, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 1, 1, 2, 0, 2, 2, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 2, 0, 2, 1, 2, 0, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 1,\n",
       "       2, 2, 1, 1, 1, 0, 1, 1, 2, 1, 0, 0, 0, 0, 2, 2, 2, 1, 0, 0, 2, 1,\n",
       "       2, 0, 2, 1, 2, 1, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       0, 2, 0, 2, 0, 0, 1, 2, 2, 2, 1, 1, 2, 0, 2, 2, 0, 1, 2, 0, 2, 0,\n",
       "       1, 1, 2, 0, 2, 2, 1, 0, 0, 2, 1, 1])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_raw = y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f6f565dcd68>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a list of features for later\n",
    "feature_list = list(X.columns)\n",
    "# Convert to numpy array\n",
    "X = np.array(X).astype(float)\n",
    "y = pd.get_dummies(y).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157, 657) (31, 657) (22, 657)\n"
     ]
    }
   ],
   "source": [
    "# split into train, test, val \n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio, random_state = RANDOM_STATE)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = RANDOM_STATE) \n",
    "\n",
    "print(X_train.shape, X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2026044662936039"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(X))/np.sum(~np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[~np.isnan(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.        , 1.        , 0.        , ..., 0.        , 0.69314718,\n",
       "       0.69314718])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-b9795800ebe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model on training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    302\u001b[0m             )\n\u001b[1;32m    303\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0;32m--> 304\u001b[0;31m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    801\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 646\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     98\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     (type_err,\n\u001b[0;32m--> 100\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m    101\u001b[0m             )\n\u001b[1;32m    102\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of total examples is  210\n",
      "indexes for splitting between train/val/test are  [168, 189]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_features()\n",
    "# split 10% of examples into val, and 10% into test\n",
    "util.save_matrices_to_disk(\n",
    "    X, y, [0.1, 0.1], saves_directory, model_prefix, num_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = util.load_matrices_from_disk(\n",
    "        saves_directory, model_prefix, num_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.69314718,  0.69314718],\n",
       "       [ 2.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.69314718,  0.69314718],\n",
       "       [ 2.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.69314718,  0.69314718],\n",
       "       ...,\n",
       "       [ 2.        ,  1.        ,  0.        , ...,  0.04      ,\n",
       "         0.69314718,  0.69314718],\n",
       "       [20.        ,  1.        ,  0.        , ...,  0.07142857,\n",
       "         0.99727152,  0.99727152],\n",
       "       [ 2.        ,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1,\n",
       "       1, 1, 2, 2, 2, 2, 2, 1, 0, 0, 0, 1, 2, 0, 1, 2, 0, 0, 1, 2, 0, 2,\n",
       "       1, 2, 2, 0, 1, 0, 0, 1, 1, 0, 2, 2, 0, 0, 2, 2, 1, 0, 2, 2, 2, 2,\n",
       "       1, 1, 1, 2, 1, 0, 0, 1, 0, 2, 0, 2, 2, 1, 0, 2, 2, 1, 2, 2, 1, 1,\n",
       "       0, 0, 2, 1, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 2, 2, 1, 1, 0, 2,\n",
       "       1, 2, 0, 2, 2, 1, 1, 0, 1, 2, 2, 0, 0, 2, 1, 1, 0, 0, 2, 0, 2, 1,\n",
       "       0, 2, 2, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 2, 0, 2, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "pred = pd.get_dummies(y_train)\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "pred.iloc[:,5:].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/pytorch-1.4-gpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
